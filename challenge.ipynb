{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb0b565-329c-4ed5-b91b-8867db86813d",
   "metadata": {},
   "source": [
    "Welcome to the Artifact coding challenge ! We hope you'll have fun and wish you best of luck ðŸ˜€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b79bb-96b8-47d8-b1f3-412f26ba2b85",
   "metadata": {},
   "source": [
    "Albert and the ear shells\n",
    "========================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b227a79c-a665-4f95-a8d0-b4edd8cd5135",
   "metadata": {},
   "source": [
    "![natural-iridescent-abalone-shell.png](natural-iridescent-abalone-shell.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf229ed-5084-4ceb-833d-c4604e6bcd7e",
   "metadata": {},
   "source": [
    "Ear shells, also known as abalone, are marine snails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ea6f5-b1e5-4866-b0fb-9b534dc8485c",
   "metadata": {},
   "source": [
    "The age of ear shells can be determined by cutting the shell through the cone, staining it, and counting the number of rings through a microscope - a boring and time-consuming task. \n",
    "\n",
    "**Albert**, a scientist and **ear shells** specialist, needs your help. He has collected data on his favorite sea creature and asks you to help him understand it. Then, he would like you to develop a model to predict the age of ear shells using other measurements which are easier to obtain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b660af3e-195c-4682-8210-65ede14a6f7c",
   "metadata": {},
   "source": [
    "# Part 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81bdb13-0c07-4778-8677-af9ebe58d09a",
   "metadata": {},
   "source": [
    "Please include any setup code (including imports) in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aecbb4da-97d0-4763-815f-1f71a6623ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cc284d-5250-48b1-8f72-f266bfcd94ca",
   "metadata": {},
   "source": [
    "# Part 1: Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225f9fcc-8653-49ce-a5ce-4c21e6f41e21",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loading, processing and exploring data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed54525-19b6-4ed9-9344-f99c5bab77c1",
   "metadata": {},
   "source": [
    "Albert has provided you the dataset `earshells.csv`. Please load it and do what every diligent Data Scientist should do when received a new dataset !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18468ad5-7f65-4172-aa8c-23e49d5ec3a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subset sex    length  diameter    height  weight_whole  weight_shucked  \\\n",
      "0  train   I  0.349544  0.260194  0.074504      0.179963        0.089707   \n",
      "1  train   F  0.545249  0.439866  0.134915      0.918132        0.428983   \n",
      "2   test   F  0.649654  0.544545  0.175080      1.524459        0.590134   \n",
      "3  train   I  0.500003  0.394566  0.140912      0.621133        0.292336   \n",
      "4  train   I  0.439268  0.335001  0.110040      0.389429        0.175157   \n",
      "5  train   I  0.294596  0.220013  0.084899      0.129350        0.058167   \n",
      "6  train   I  0.475259  0.364612  0.120313      0.518502        0.268031   \n",
      "7  train   M  0.549885  0.451143  0.149154      1.014219        0.407824   \n",
      "8  train   I  0.464834  0.355262  0.119326      0.580638        0.254973   \n",
      "9   test   I  0.379859  0.290154  0.100127      0.236797        0.107936   \n",
      "\n",
      "   weight_viscera  weight_shell  rings      price  \n",
      "0        0.024760      0.054516    5.0   1.205721  \n",
      "1        0.201751      0.237840   10.0  18.403463  \n",
      "2        0.325970      0.495506   10.0  31.455767  \n",
      "3        0.120165      0.195429    9.0   5.647747  \n",
      "4        0.083279      0.110899    7.0   1.966989  \n",
      "5        0.027437      0.036809    5.0   0.229251  \n",
      "6        0.109303      0.136601    8.0   4.142997  \n",
      "7        0.201920      0.287036   10.0  16.212238  \n",
      "8        0.091545      0.183995    8.0   7.455883  \n",
      "9        0.039838      0.082200    6.0   2.284661  \n",
      "       subset   sex       length     diameter       height  weight_whole  \\\n",
      "count    3174  3174  3174.000000  3174.000000  3174.000000   3174.000000   \n",
      "unique      2     3          NaN          NaN          NaN           NaN   \n",
      "top     train     I          NaN          NaN          NaN           NaN   \n",
      "freq     2857  1195          NaN          NaN          NaN           NaN   \n",
      "mean      NaN   NaN     0.514369     0.400696     0.137644      0.762393   \n",
      "std       NaN   NaN     0.134614     0.127081     0.085251      0.467023   \n",
      "min       NaN   NaN     0.000000     0.000000     0.000000      0.000000   \n",
      "25%       NaN   NaN     0.430444     0.330102     0.105422      0.380190   \n",
      "50%       NaN   NaN     0.525349     0.409146     0.135162      0.709052   \n",
      "75%       NaN   NaN     0.604510     0.474409     0.159900      1.084979   \n",
      "max       NaN   NaN     1.973813     3.491197     2.662290      2.987259   \n",
      "\n",
      "        weight_shucked  weight_viscera  weight_shell        rings        price  \n",
      "count      3174.000000     3174.000000   3174.000000  3143.000000  3143.000000  \n",
      "unique             NaN             NaN           NaN          NaN          NaN  \n",
      "top                NaN             NaN           NaN          NaN          NaN  \n",
      "freq               NaN             NaN           NaN          NaN          NaN  \n",
      "mean          0.342232        0.171397      0.214670     8.688514    12.009276  \n",
      "std           0.221347        0.136742      0.134140     1.652502     8.961170  \n",
      "min           0.000000        0.000000      0.000000     5.000000     0.100000  \n",
      "25%           0.164375        0.081057      0.111309     8.000000     4.404896  \n",
      "50%           0.311254        0.153026      0.200179     9.000000    10.000912  \n",
      "75%           0.489777        0.238163      0.296504    10.000000    18.243623  \n",
      "max           1.905003        3.196680      1.545075    11.000000    52.901790  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3174 entries, 0 to 3173\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   subset          3174 non-null   object \n",
      " 1   sex             3174 non-null   object \n",
      " 2   length          3174 non-null   float64\n",
      " 3   diameter        3174 non-null   float64\n",
      " 4   height          3174 non-null   float64\n",
      " 5   weight_whole    3174 non-null   float64\n",
      " 6   weight_shucked  3174 non-null   float64\n",
      " 7   weight_viscera  3174 non-null   float64\n",
      " 8   weight_shell    3174 non-null   float64\n",
      " 9   rings           3143 non-null   float64\n",
      " 10  price           3143 non-null   float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 272.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('earshells.csv') #Reading the dataframe\n",
    "print(df.head(10)) #Show first 10 results to visuilize data\n",
    "print(df.describe(include='all')) #Statistic\n",
    "print(df.info()) #general info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82705c27",
   "metadata": {},
   "source": [
    "From that we see: \n",
    "1) First 2 columns are not numeric values (Have to encode them);<br>\n",
    "2) Total number of rows 3174. In last 2 columns we have a missing data (Have to deal with it);<br>\n",
    "3) We have already data are split into training and test sets? (Values of 1st column. Have to form tests by this rule);<br> \n",
    "4) Other statistical info.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622122f2",
   "metadata": {},
   "source": [
    "### Dealing with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fefbbf1",
   "metadata": {},
   "source": [
    "<i>Here I will replace missing data in all columns with numeric values (from 2 to last) with a mean value calculated for each column. Using <b>SimpleImputer</b> from <b>sklearn</b> library.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c60473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3174 entries, 0 to 3173\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   subset          3174 non-null   object \n",
      " 1   sex             3174 non-null   object \n",
      " 2   length          3174 non-null   float64\n",
      " 3   diameter        3174 non-null   float64\n",
      " 4   height          3174 non-null   float64\n",
      " 5   weight_whole    3174 non-null   float64\n",
      " 6   weight_shucked  3174 non-null   float64\n",
      " 7   weight_viscera  3174 non-null   float64\n",
      " 8   weight_shell    3174 non-null   float64\n",
      " 9   rings           3174 non-null   float64\n",
      " 10  price           3174 non-null   float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 272.9+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer.fit(df.iloc[:, 2:len(df.columns)])\n",
    "df.iloc[:, 2:len(df.columns)] = imputer.transform(df.iloc[:, 2:len(df.columns)])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e0c666",
   "metadata": {},
   "source": [
    "### Dividing to subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fc5537",
   "metadata": {},
   "source": [
    "<i>In this chapter I divide dataframe onto training and test subsets of independent (X) variables and dependent (y). In feature frame (X) after dividing I got rid out of \"subset\" column.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31352312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3174\n",
      "[['I' 0.3495442836075593 0.2601940906334086 ... 0.0247599507832135\n",
      "  0.0545161929959864 5.0]\n",
      " ['F' 0.5452490400598211 0.4398656370726855 ... 0.2017510973532418\n",
      "  0.2378398030284065 10.0]\n",
      " ['I' 0.5000031723831203 0.3945664355082028 ... 0.1201647205750157\n",
      "  0.1954293870087821 9.0]\n",
      " ...\n",
      " ['I' 0.3450474020089475 0.2553387214243274 ... 0.0363349303647198\n",
      "  0.0553393824263176 6.0]\n",
      " ['M' 0.749726251499644 0.5547359557667633 ... 0.5223463012914071\n",
      "  0.5278917571509596 11.0]\n",
      " ['F' 0.7201674037615454 0.5506174994453702 ... 0.3250788916683267\n",
      "  0.4348239342922483 10.0]]\n"
     ]
    }
   ],
   "source": [
    "grouped = df.groupby(df.subset)\n",
    "df_train = grouped.get_group('train')\n",
    "df_test = grouped.get_group('test')\n",
    "X_train = df_train.iloc[:,1:-1].values\n",
    "X_test = df_test.iloc[:,1:-1].values\n",
    "y_train = df_train.iloc[:, -1].values\n",
    "y_test = df_test.iloc[:, -1].values\n",
    "total = len(X_train)+len(X_test)\n",
    "print(total)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f86ada",
   "metadata": {},
   "source": [
    "### Encoding the categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558230a3",
   "metadata": {},
   "source": [
    "<i>Here I am encoding the sex column by <b>OneHotEncoder</b> from the <b>sci-kit learn</b> library. As we can see there are 3 different values of \"sex\" parameter encoded into 3 columns.</i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c52355fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 ... 0.0247599507832135 0.0545161929959864 5.0]\n",
      " [1.0 0.0 0.0 ... 0.2017510973532418 0.2378398030284065 10.0]\n",
      " [0.0 1.0 0.0 ... 0.1201647205750157 0.1954293870087821 9.0]\n",
      " ...\n",
      " [0.0 1.0 0.0 ... 0.0363349303647198 0.0553393824263176 6.0]\n",
      " [0.0 0.0 1.0 ... 0.5223463012914071 0.5278917571509596 11.0]\n",
      " [1.0 0.0 0.0 ... 0.3250788916683267 0.4348239342922483 10.0]]\n",
      "[[1.0 0.0 0.0 ... 0.3259701403307138 0.4955058887031087 10.0]\n",
      " [0.0 1.0 0.0 ... 0.0398381866156518 0.0821997873194008 6.0]\n",
      " [0.0 1.0 0.0 ... 0.1412284656040897 0.1199518030325547 9.0]\n",
      " ...\n",
      " [0.0 1.0 0.0 ... 0.0176725751633301 0.0252668992742599 7.0]\n",
      " [1.0 0.0 0.0 ... 0.308514168254535 0.4046327094806584 11.0]\n",
      " [0.0 0.0 1.0 ... 0.1971943616800289 0.2749568773220962 10.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "print(X_train)\n",
    "X_test = np.array(ct.fit_transform(X_test))\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf89d40",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79895f40",
   "metadata": {},
   "source": [
    "<i>Here I am scaling features in columns from \"length\" to \"rings\". Actually, from the data analysis in 3.1, it is seems for me that I can scale only \"rings\" column, others are ok.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c344bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 ... -1.0595108777028999 -1.1881799433271185\n",
      "  -2.242383689900623]\n",
      " [1.0 0.0 0.0 ... 0.21505263117063042 0.1635773530936 0.7982002323911073]\n",
      " [0.0 1.0 0.0 ... -0.3724740371285111 -0.14914062845076875\n",
      "  0.19008344793276122]\n",
      " ...\n",
      " [0.0 1.0 0.0 ... -0.9761561626425794 -1.182110063301355\n",
      "  -1.634266905442277]\n",
      " [0.0 0.0 1.0 ... 2.5237497382193097 2.302308121361314 1.4063170168494534]\n",
      " [1.0 0.0 0.0 ... 1.1031711009929288 1.6160620421519545\n",
      "  0.7982002323911073]]\n",
      "[[1.0 0.0 0.0 ... 1.1095892357099753 2.0635072709549647\n",
      "  0.7982002323911073]\n",
      " [0.0 1.0 0.0 ... -0.9509282195154674 -0.9840518410537195\n",
      "  -1.634266905442277]\n",
      " [0.0 1.0 0.0 ... -0.22078802743507364 -0.7056830991016017\n",
      "  0.19008344793276122]\n",
      " ...\n",
      " [0.0 1.0 0.0 ... -1.1105490822337079 -1.403852906545028\n",
      "  -1.026150120983931]\n",
      " [1.0 0.0 0.0 ... 0.9838838235954211 1.3934436439013005\n",
      "  1.4063170168494534]\n",
      " [0.0 0.0 1.0 ... 0.18223828355374855 0.4372642829408359\n",
      "  0.7982002323911073]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scX = StandardScaler()\n",
    "X_train[:, 3:] = scX.fit_transform(X_train[:, 3:])\n",
    "X_test[:, 3:] = scX.transform(X_test[:, 3:])\n",
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb318c6-7834-4d12-88ff-1d430926199f",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e75634-9619-488a-a7a0-cb8c9dc5d9f6",
   "metadata": {},
   "source": [
    "Albert needs your help getting a deeper understanding of one particular aspect of this data: the price of ear shells. Can you help him ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b316264b-f536-49f3-9ef1-1d491307c35b",
   "metadata": {},
   "source": [
    "### Question 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1435c8-04c2-43a3-8d2d-59d7b6e600dc",
   "metadata": {},
   "source": [
    "What's the **average price** for ear shells with a **diameter** falling outside the interquartile range (of diameter) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ff342",
   "metadata": {},
   "source": [
    "<i>Interquartile range is Q3-Q1, therefore we are looking for values of diameter less than Q1 and higher than Q3.</i> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "492c6f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avarage price for ear shells outside the interquartile range of diameter is 13.09 \n"
     ]
    }
   ],
   "source": [
    "q1 = df['diameter'].quantile(q=0.25)\n",
    "q3 = df['diameter'].quantile(q=0.75)\n",
    "numb = 0\n",
    "t_sum = 0\n",
    "for i in range(0, len(df)):\n",
    "    if (df.iloc[i, 3] < q1 or df.iloc[i, 3] > q3):\n",
    "         t_sum += df.iloc[i, 10]\n",
    "         numb += 1\n",
    "print('The avarage price for ear shells outside the interquartile range of diameter is {:.2f} '.format(t_sum/numb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805854b-eb80-4b62-a210-d622b00a6743",
   "metadata": {},
   "source": [
    "### Question 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d492d02-2b40-4929-b1fe-5692865c3cd9",
   "metadata": {},
   "source": [
    "Albert would like to understand which factors / attributes have been used to determine the price. Please provide him with **one clear visualization** which explicits the dependency between the price and the most relevant attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577155c1",
   "metadata": {},
   "source": [
    "<i>Wow, that was a bit hard part and I think, here I need to practice more. I got scores for each feature in <b>SelectKBest</b> method for <b>f_regression</b> function. From the bar plot I can tell that we should concentrate only on 2, maximum 3, values with a highest score.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68e44bac-f2bb-4980-aafa-e4ad0c8e2356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_regression\n",
    "select = SelectKBest(score_func=f_regression, k='all')\n",
    "z = select.fit(X_train, y_train)\n",
    "scores = pd.DataFrame(z.scores_)\n",
    "#print(scores)\n",
    "x1=df.columns.values.tolist()\n",
    "y1=scores.iloc[:,-1].tolist()\n",
    "#print(x1, y1)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.bar(x1,y1)\n",
    "plt.setp(ax.get_xticklabels(), rotation=30, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc46ff-2485-457b-9fac-ae9bfe8f9eb2",
   "metadata": {},
   "source": [
    "# Part 2: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4a1708-4d3b-47c8-8ac6-7070cd5fbdc6",
   "metadata": {},
   "source": [
    "Albert loves ML ! He asks you to use your ML skills to train a model that will predict the **number of rings** based on the other attributes.\n",
    "\n",
    "Albert was kind enough to pre-assign the dataset samples to train-test with the `subset` attribute. `test` samples should obviously not be used during the training procedure !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dc63f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62691747",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Which model will you choose to accomplish this task? Briefly explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37630132",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "<i>While we are looking for prediction of continuous numeric value, we are aiming for some sort of regression. I guess it is better to try different and choose the best. But, before, I have to slightly modify training and test sets to make the <b>number of rings</b> a target</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d088e3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear regression accuracy is 29.07 %\n",
      "Polynomial regression accuracy is 35.85 %\n",
      "Random forest regression accuracy is 17.36 %\n",
      "Decision tree regression accuracy is -13.42 %\n",
      "XGBoost accuracy is 31.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yehor\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR accuracy is 34.07 %\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.iloc[:,6:7].values\n",
    "X_test = df_test.iloc[:,6:7].values\n",
    "y_train = df_train.iloc[:, 9].values\n",
    "y_test = df_test.iloc[:, 9].values\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Multiple linear regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "poly_reg = PolynomialFeatures(degree = 5)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_poly, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(poly_reg.transform(X_test))\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Polynomial regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Random forest regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Decision tree regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "classifier = XGBRegressor()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print('XGBoost accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1,1))\n",
    "\n",
    "# Training the SVR model on the Training set\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(X_test)).reshape(-1,1))\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('SVR accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466fb56",
   "metadata": {},
   "source": [
    "<i>In this case I would like to add back features and rechek</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b0b7f82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear regression accuracy is 46.74 %\n",
      "Polynomial regression accuracy is 46.69 %\n",
      "Random forest regression accuracy is 56.45 %\n",
      "Decision tree regression accuracy is 20.47 %\n",
      "XGBoost accuracy is 50.69 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yehor\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR accuracy is 56.91 %\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.iloc[:,1:9].values\n",
    "X_test = df_test.iloc[:,1:9].values\n",
    "y_train = df_train.iloc[:, 9].values\n",
    "y_test = df_test.iloc[:, 9].values\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.fit_transform(X_test))\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Multiple linear regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "poly_reg = PolynomialFeatures(degree = 1)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_poly, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(poly_reg.transform(X_test))\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Polynomial regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "# CHANGING DEGREE IN POLYNOMIAL REGRESSION SHOWS THAT TREND IS LINEAR\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Random forest regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Decision tree regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "classifier = XGBRegressor()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print('XGBoost accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1,1))\n",
    "\n",
    "# Training the SVR model on the Training set\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = sc_y.inverse_transform(regressor.predict(sc_X.transform(X_test)).reshape(-1,1))\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('SVR accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b93d5a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple linear regression accuracy is 46.64 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yehor\\AppData\\Local\\Temp\\ipykernel_15584\\2091153119.py:36: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  regressor.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest regression accuracy is 56.79 %\n",
      "Decision tree regression accuracy is 21.01 %\n",
      "XGBoost accuracy is -2754.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yehor\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR accuracy is 56.91 %\n",
      "Polynomial regression accuracy is 46.76 %\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.iloc[:,1:9].values\n",
    "X_test = df_test.iloc[:,1:9].values\n",
    "y_train = df_train.iloc[:, 9].values\n",
    "y_test = df_test.iloc[:, 9].values\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X_train = np.array(ct.fit_transform(X_train))\n",
    "X_test = np.array(ct.fit_transform(X_test))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "y_train = sc_y.fit_transform(y_train.reshape(-1,1))\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = sc_y.inverse_transform(regressor.predict(X_test))\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Multiple linear regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "\n",
    "# CHANGING DEGREE IN POLYNOMIAL REGRESSION SHOWS THAT TREND IS LINEAR\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = sc_y.inverse_transform([regressor.predict(X_test)]).ravel()\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Random forest regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "regressor = DecisionTreeRegressor(random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = sc_y.inverse_transform([regressor.predict(X_test)]).ravel()\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Decision tree regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "classifier = XGBRegressor()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print('XGBoost accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "# Training the SVR model on the Training set\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = sc_y.inverse_transform([regressor.predict(X_test)]).ravel()\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('SVR accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "poly_reg = PolynomialFeatures(degree = 1)\n",
    "X_poly = poly_reg.fit_transform(X_train)\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_poly, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = sc_y.inverse_transform(regressor.predict(poly_reg.transform(X_test)))\n",
    "\n",
    "# Evaluating the Model Performance\n",
    "from sklearn.metrics import r2_score\n",
    "print('Polynomial regression accuracy is {:.2f} %'.format(r2_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727a45b2",
   "metadata": {},
   "source": [
    "<i>With all features accuracy is higher, maybe, we should carefully specify valuable features. Next step is Grid search for better parameters of the regression models</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568952ec-c322-4c01-bd83-b8e72aba9cfd",
   "metadata": {},
   "source": [
    "### Question 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb0a55-4211-4537-8ffc-7526e814ad5c",
   "metadata": {},
   "source": [
    "Which metric would you choose to communicate the performance of your model to Albert ? Briefly explain why"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e045537",
   "metadata": {},
   "source": [
    "<i><b>r square metrics</b> describes how model fits a dataset</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c3f64a-ba5e-4e33-8b3a-354cef4bd8d5",
   "metadata": {},
   "source": [
    "### Question 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f39cc-1a73-4d6b-b22f-1f5c399106ff",
   "metadata": {},
   "source": [
    "How's your model performing ? Please provide the value of your chosen metric on the **test set** and briefly discuss it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebca7ab",
   "metadata": {},
   "source": [
    "<i>Not so good. The best <b>r square</b> parameters I have got for SVR and Random forest models, but they not higher 57%. I did't check for data that stand out the trend and did't do the parameters tune for each model </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fd21af-69b8-41b9-8a89-d9b0bb264520",
   "metadata": {},
   "source": [
    "# The end !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88fa073-627e-4bc7-9052-4afa4733d14f",
   "metadata": {},
   "source": [
    "Thank you for participating in this challenge, we hope you enjoyed it !\n",
    "\n",
    "Don't forget to submit your work by email, including a zip file with:\n",
    "- your notebook `challenge.ipynb`\n",
    "- an export of your notebook as HTML `challenge.html`\n",
    "- an image of your visualization for question 1.2\n",
    "- a `requirements.txt` file listing all the dependencies you have used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2a7c2-da41-45d9-b3b3-58223d6fc872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
